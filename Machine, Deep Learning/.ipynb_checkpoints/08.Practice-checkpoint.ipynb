{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1863406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3)\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터\n",
    "import numpy as np\n",
    "loaded_data = np.loadtxt('./test01.csv', delimiter=',')\n",
    "loaded_data\n",
    "\n",
    "x_data = loaded_data[:, 0:-1]\n",
    "t_data = loaded_data[:, -1:]\n",
    "\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb238f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수\n",
    "def loss_func(x, t):\n",
    "    y = np.dot(x,W)+b\n",
    "    \n",
    "    return (np.sum((t-y)**2)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af433f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#미분함수\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-5\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp = x[idx]\n",
    "        \n",
    "        x[idx] = float(tmp)+delta_x\n",
    "        fx1 = f(x)\n",
    "        #fx1=f(tmp+delta_x)로 하지 않는 이유는, f값을 구할 때 x가 여러개의 값을 갖는다면, 다른 값들도 고려해야하기 때문이다.\n",
    "        #fx1=f(tmp+delta_x)로 하면, 일단 파라미터가 잘못된거다. f는 여러개의 값을 기대하는데, 하나의 값만 넘겨준 것이기 때문\n",
    "        \n",
    "        x[idx] = float(tmp)-delta_x\n",
    "        fx2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fx1-fx2)/(2*delta_x)\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d0a38a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 W =  [[1.01618602]\n",
      " [0.65446565]\n",
      " [0.14356519]] b =  [0.63783859] \n",
      "error_value =  336.51910792205547\n",
      "step =  400 W =  [[1.01511157]\n",
      " [0.66891938]\n",
      " [0.3433808 ]] b =  [0.63466127] \n",
      "error_value =  23.99806090264527\n",
      "step =  800 W =  [[0.94995815]\n",
      " [0.62337365]\n",
      " [0.45125484]] b =  [0.63080758] \n",
      "error_value =  19.52602495665015\n",
      "step =  1200 W =  [[0.89131817]\n",
      " [0.5874251 ]\n",
      " [0.54342171]] b =  [0.62683533] \n",
      "error_value =  16.23562863212364\n",
      "step =  1600 W =  [[0.83852057]\n",
      " [0.55930325]\n",
      " [0.62226352]] b =  [0.6227617] \n",
      "error_value =  13.801812645457153\n",
      "step =  2000 W =  [[0.7909665 ]\n",
      " [0.53754576]\n",
      " [0.68979109]] b =  [0.61860132] \n",
      "error_value =  11.991601463376217\n",
      "step =  2400 W =  [[0.74812112]\n",
      " [0.52094636]\n",
      " [0.74770286]] b =  [0.61436661] \n",
      "error_value =  10.637488268818226\n",
      "step =  2800 W =  [[0.70950633]\n",
      " [0.50851139]\n",
      " [0.79743434]] b =  [0.61006815] \n",
      "error_value =  9.618614289130985\n",
      "step =  3200 W =  [[0.67469442]\n",
      " [0.49942369]\n",
      " [0.84019961]] b =  [0.60571495] \n",
      "error_value =  8.847440709443505\n",
      "step =  3600 W =  [[0.64330252]\n",
      " [0.49301242]\n",
      " [0.87702627]] b =  [0.60131468] \n",
      "error_value =  8.26029469225673\n",
      "step =  4000 W =  [[0.61498759]\n",
      " [0.48872798]\n",
      " [0.90878467]] b =  [0.59687392] \n",
      "error_value =  7.810650827627418\n",
      "step =  4400 W =  [[0.58944212]\n",
      " [0.4861211 ]\n",
      " [0.93621263]] b =  [0.59239826] \n",
      "error_value =  7.4643463693494585\n",
      "step =  4800 W =  [[0.56639027]\n",
      " [0.48482551]\n",
      " [0.95993612]] b =  [0.58789252] \n",
      "error_value =  7.19616545270703\n",
      "step =  5200 W =  [[0.54558446]\n",
      " [0.48454343]\n",
      " [0.98048667]] b =  [0.58336079] \n",
      "error_value =  6.987394002905964\n",
      "step =  5600 W =  [[0.52680235]\n",
      " [0.4850336 ]\n",
      " [0.99831608]] b =  [0.57880662] \n",
      "error_value =  6.824064177583633\n",
      "step =  6000 W =  [[0.50984416]\n",
      " [0.48610134]\n",
      " [1.01380874]] b =  [0.57423303] \n",
      "error_value =  6.695689638284396\n",
      "step =  6400 W =  [[0.49453031]\n",
      " [0.4875902 ]\n",
      " [1.02729199]] b =  [0.56964263] \n",
      "error_value =  6.594351027314137\n",
      "step =  6800 W =  [[0.4806993 ]\n",
      " [0.48937518]\n",
      " [1.03904495]] b =  [0.56503768] \n",
      "error_value =  6.514031975952988\n",
      "step =  7200 W =  [[0.4682058 ]\n",
      " [0.49135699]\n",
      " [1.04930584]] b =  [0.56042011] \n",
      "error_value =  6.450134869803797\n",
      "step =  7600 W =  [[0.45691902]\n",
      " [0.49345739]\n",
      " [1.05827822]] b =  [0.55579159] \n",
      "error_value =  6.399126016166307\n",
      "step =  8000 W =  [[0.44672118]\n",
      " [0.49561526]\n",
      " [1.06613624]] b =  [0.55115358] \n",
      "error_value =  6.358274304358433\n",
      "step =  8400 W =  [[0.43750621]\n",
      " [0.49778342]\n",
      " [1.0730291 ]] b =  [0.54650733] \n",
      "error_value =  6.325457685661471\n",
      "step =  8800 W =  [[0.42917851]\n",
      " [0.49992599]\n",
      " [1.07908475]] b =  [0.54185394] \n",
      "error_value =  6.299019064497179\n",
      "step =  9200 W =  [[0.42165194]\n",
      " [0.50201618]\n",
      " [1.08441308]] b =  [0.53719436] \n",
      "error_value =  6.277658359029759\n",
      "step =  9600 W =  [[0.41484883]\n",
      " [0.50403449]\n",
      " [1.08910861]] b =  [0.5325294] \n",
      "error_value =  6.260351171788455\n",
      "step =  10000 W =  [[0.40869913]\n",
      " [0.50596729]\n",
      " [1.09325274]] b =  [0.52785979] \n",
      "error_value =  6.246287142149884\n",
      "step =  10400 W =  [[0.40313965]\n",
      " [0.50780558]\n",
      " [1.09691566]] b =  [0.52318616] \n",
      "error_value =  6.234822937921215\n",
      "step =  10800 W =  [[0.39811341]\n",
      " [0.50954398]\n",
      " [1.100158  ]] b =  [0.51850905] \n",
      "error_value =  6.225446198508052\n",
      "step =  11200 W =  [[0.39356895]\n",
      " [0.51117999]\n",
      " [1.10303221]] b =  [0.51382896] \n",
      "error_value =  6.217747719735461\n",
      "step =  11600 W =  [[0.38945984]\n",
      " [0.5127133 ]\n",
      " [1.1055837 ]] b =  [0.50914629] \n",
      "error_value =  6.211399878267968\n",
      "step =  12000 W =  [[0.38574418]\n",
      " [0.51414526]\n",
      " [1.1078519 ]] b =  [0.50446143] \n",
      "error_value =  6.206139808317897\n",
      "step =  12400 W =  [[0.38238411]\n",
      " [0.51547846]\n",
      " [1.10987103]] b =  [0.49977469] \n",
      "error_value =  6.201756219338211\n",
      "step =  12800 W =  [[0.37934546]\n",
      " [0.5167164 ]\n",
      " [1.1116709 ]] b =  [0.49508637] \n",
      "error_value =  6.198079019440413\n",
      "step =  13200 W =  [[0.37659736]\n",
      " [0.51786321]\n",
      " [1.11327747]] b =  [0.49039672] \n",
      "error_value =  6.194971112956925\n",
      "step =  13600 W =  [[0.37411192]\n",
      " [0.51892342]\n",
      " [1.11471341]] b =  [0.48570596] \n",
      "error_value =  6.192321891706749\n",
      "step =  14000 W =  [[0.37186395]\n",
      " [0.51990181]\n",
      " [1.11599852]] b =  [0.48101429] \n",
      "error_value =  6.190042052314052\n",
      "step =  14400 W =  [[0.36983069]\n",
      " [0.52080326]\n",
      " [1.11715016]] b =  [0.47632188] \n",
      "error_value =  6.188059456589695\n",
      "step =  14800 W =  [[0.36799158]\n",
      " [0.52163267]\n",
      " [1.11818352]] b =  [0.4716289] \n",
      "error_value =  6.186315815925607\n",
      "step =  15200 W =  [[0.36632802]\n",
      " [0.52239487]\n",
      " [1.11911196]] b =  [0.46693548] \n",
      "error_value =  6.184764029227272\n",
      "step =  15600 W =  [[0.36482321]\n",
      " [0.52309455]\n",
      " [1.11994721]] b =  [0.46224173] \n",
      "error_value =  6.183366041035605\n",
      "step =  16000 W =  [[0.36346197]\n",
      " [0.52373623]\n",
      " [1.12069961]] b =  [0.45754778] \n",
      "error_value =  6.182091115033623\n",
      "step =  16400 W =  [[0.36223057]\n",
      " [0.52432425]\n",
      " [1.12137827]] b =  [0.45285371] \n",
      "error_value =  6.180914440201536\n",
      "step =  16800 W =  [[0.36111659]\n",
      " [0.5248627 ]\n",
      " [1.12199123]] b =  [0.44815962] \n",
      "error_value =  6.179816004040553\n",
      "step =  17200 W =  [[0.36010884]\n",
      " [0.52535547]\n",
      " [1.12254561]] b =  [0.44346558] \n",
      "error_value =  6.178779680694521\n",
      "step =  17600 W =  [[0.35919714]\n",
      " [0.52580621]\n",
      " [1.12304771]] b =  [0.43877165] \n",
      "error_value =  6.177792492326155\n"
     ]
    }
   ],
   "source": [
    "#learning 함수\n",
    "learning_rate = 1e-5\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "W = np.random.rand(3,1) #이거는 데이터에 따라서 변경되는 값\n",
    "b = np.random.rand(1)\n",
    "\n",
    "for step in range(18000):\n",
    "    W -= learning_rate*numerical_derivative(f, W)\n",
    "    b -= learning_rate*numerical_derivative(f, b)\n",
    "    \n",
    "    if(step % 400 == 0):\n",
    "        print('step = ', step, 'W = ', W, 'b = ', b, '\\nerror_value = ', loss_func(x_data, t_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987e4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict함수\n",
    "def predict(x):\n",
    "    y = np.dot(x,W)+b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6978f91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([191.20300415])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(np.array([100, 98, 92]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
